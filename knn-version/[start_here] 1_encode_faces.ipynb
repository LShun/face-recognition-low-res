{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition in Low Resolution\n",
    "\n",
    "This file is for step 1: face encoding.\n",
    "\n",
    "Be sure to run all code blocks. Click the code blocks, then use `CTRL`+`Enter` to run. Be sure you run them in sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Encode faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose of this code is to quantify faces inside training set. We will be using a network that is already trained to create 128-d embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.1: Imports & Path Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Imports & Path set successfully!\n"
     ]
    }
   ],
   "source": [
    "# import required packages to run\n",
    "from imutils import paths # to get paths\n",
    "import cv2 # for face detection\n",
    "import os # for file system access\n",
    "import pickle # for storing embeddings\n",
    "import face_recognition # for embeddings\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "datasetPathAbs = os.path.abspath(args[\"dataset\"])\n",
    "\n",
    "if not os.path.exists(args[\"dataset\"]):\n",
    "    print(\"[WARN] \", datasetPathAbs, \"folder does not exist!\")\n",
    "    print(\"Create a folder there, and put subfolders named as the person's name (e.g. 'Long_Shun') and put images inside!\")\n",
    "    args[\"start_check\"] = \"false\"\n",
    "elif not os.access('.', os.W_OK):\n",
    "    print(\"[ERROR] Insufficient permission to write to current directory. You might want to check write permissions of the folder.\")\n",
    "    args[\"start_check\"] = \"false\"\n",
    "else:\n",
    "    print(\"[INFO] Imports & Path set successfully!\")\n",
    "    args[\"start_check\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.2: Detect & encode faces\n",
    "\n",
    "Detect face, encode them into the system, and then store the encodings inside the .pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOTE] Arguments set successfully\n",
      "[NOTE] Quantifying Faces\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1104/974459084.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# get input image paths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[NOTE] Quantifying Faces\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mimagePaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"dataset\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mimagePaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[ERROR] No image found in '\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatasetPathAbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"' did you forgot to put the images in the dataset folder?\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'paths' is not defined"
     ]
    }
   ],
   "source": [
    "# set arguments\n",
    "args = {}\n",
    "args[\"dataset\"] = \"dataset\\dataset-full-res\"\n",
    "args[\"detection_method\"] = \"hog\" # choose between 'hog', 'cnn'\n",
    "args[\"encodings\"] = \"encodings.pickle\"\n",
    "args[\"start_check\"] = \"false\"\n",
    "\n",
    "print(\"[NOTE] Arguments set successfully\")\n",
    "\n",
    "# get input image paths\n",
    "print(\"[NOTE] Quantifying Faces\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "if not imagePaths:\n",
    "    print(\"[ERROR] No image found in '\", datasetPathAbs, \"' did you forgot to put the images in the dataset folder?\")\n",
    "else:\n",
    "    # initialize the list of known encodings and known names\n",
    "    knownEncodings = []\n",
    "    knownNames = []\n",
    "\n",
    "    # FOR DEBUGGING\n",
    "    #print(imagePaths)\n",
    "\n",
    "    # loop over the image paths\n",
    "    for (i, imagePath) in enumerate(imagePaths):\n",
    "        # extract the person name from the image path\n",
    "        print(\"[INFO] processing image [{}/{}]\".format(i + 1, len(imagePaths)), imagePath)\n",
    "        name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "        # load the input image and convert it from RGB (OpenCV ordering)\n",
    "        # to dlib ordering (RGB)\n",
    "        image = cv2.imread(imagePath)\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # detect the (x, y)-coordinates of the bounding boxes\n",
    "        # corresponding to each face in the input image\n",
    "        boxes = face_recognition.face_locations(rgb, model=args[\"detection_method\"])\n",
    "        print(len(boxes))\n",
    "        if len(boxes) == 0:\n",
    "            print(\"[WARN] Can't find faces! \", imagePath)\n",
    "            print(\"This image will be excluded from encoding, replace/delete the image to remove this warning.\")\n",
    "        elif len(boxes) > 1:\n",
    "            print(\"[WARN] Multiple faces found! \", imagePath)\n",
    "            print(\"This image will be excluded from encoding, replace/delete the image to remove this warning\")\n",
    "        else:\n",
    "            # compute the facial embedding for the face\n",
    "            encodings = face_recognition.face_encodings(rgb, boxes)\n",
    "\n",
    "            # loop over the encodings\n",
    "            for encoding in encodings:\n",
    "                # add each encoding + name to our set of known names and\n",
    "                # encodings\n",
    "                knownEncodings.append(encoding)\n",
    "                knownNames.append(name)\n",
    "                \n",
    "        for (top, right, bottom, left) in boxes:\n",
    "            # draw the predicted face name on the image\n",
    "            cv2.rectangle(rgb, (left, top), (right, bottom), (255, 0, 0), 1)\n",
    "        \n",
    "        # error checks\n",
    "        plt.imshow(rgb)\n",
    "        plt.title(imagePath)\n",
    "        plt.show()\n",
    "\n",
    "    # dump the facial encodings + names to disk\n",
    "    print(\"[INFO] serializing encodings...\")\n",
    "    data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "    f = open(args[\"encodings\"], \"wb\")\n",
    "    f.write(pickle.dumps(data))\n",
    "    f.close()\n",
    "    print(\"[INFO] Serialization Complete!\")\n",
    "    \n",
    "    # remove duplicates from list\n",
    "    dedupedNames = []\n",
    "    [dedupedNames.append(x) for x in knownNames if x not in dedupedNames]\n",
    "    \n",
    "    print(\"Serialized people: \", len(dedupedNames))\n",
    "    print(\"Serialized names: \", dedupedNames)\n",
    "    print(\"You can now open 2_recognize_faces_in_image Jupyter Notebook to detect the faces of the above person!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fdet import MTCNN\n",
    "\n",
    "# detector = MTCNN()\n",
    "\n",
    "# # get input image paths\n",
    "# print(\"[NOTE] Quantifying Faces\")\n",
    "# imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# # initialize the list of known encodings and known names\n",
    "# knownEncodings = []\n",
    "# knownNames = []\n",
    "\n",
    "# # FOR DEBUGGING\n",
    "# #print(imagePaths)\n",
    "\n",
    "# # loop over the image paths\n",
    "# for (i, imagePath) in enumerate(imagePaths):\n",
    "#     # extract the person name from the image path\n",
    "#     print(\"[INFO] processing image {}/{} in {}\".format(i + 1, len(imagePaths), imagePath))\n",
    "#     name = imagePath.split(os.path.sep)[-2]\n",
    "\n",
    "#     # load the input image and convert it from RGB (OpenCV ordering)\n",
    "#     # to dlib ordering (RGB)\n",
    "#     image = cv2.imread(imagePath)\n",
    "#     rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # detect the (x, y)-coordinates of the bounding boxes\n",
    "#     # corresponding to each face in the input image\n",
    "#     boxes = detector.detect(rgb)\n",
    "#     # print(boxes)\n",
    "#     # compute the facial embedding for the face\n",
    "#     # print(\"[NOTE]\", len(boxes), \" faces found in \", imagePath)\n",
    "#     for box in boxes:\n",
    "#         boxFormatted = [tuple(box.get('box'))]\n",
    "#         encodings = face_recognition.face_encodings(rgb,boxFormatted)\n",
    "#     # loop over the encodings\n",
    "#     for encoding in encodings:\n",
    "#         # add each encoding + name to our set of known names and\n",
    "#         # encodings\n",
    "#         knownEncodings.append(encoding)\n",
    "#         knownNames.append(name)\n",
    "\n",
    "# # dump the facial encodings + names to disk\n",
    "# print(\"[INFO] serializing encodings...\")\n",
    "# data = {\"encodings\": knownEncodings, \"names\": knownNames}\n",
    "# f = open(args[\"encodings\"], \"wb\")\n",
    "# f.write(pickle.dumps(data))\n",
    "# f.close()\n",
    "# print(\"[INFO] Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done?\n",
    "\n",
    "Open [Step 2: Recognize faces in image](2_recognize_faces_in_image.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
